
# This is the ReadMe for the Spotlight library used in this project

All information can be found in this [link](https://maciejkula.github.io/spotlight/index.html).

This library is designed for building recommendation systems. It provides various models and utilities for collaborative filtering and other recommendation-related tasks.


### Interactions

The data used for the recommender is based on user-item interactions (ex: when a user rates a movie).

The Spotlight library includes all necessary estructures to work with datasets containing information about how users have interacted with items. In this case, there is a class used for describing pairs of user-item interactions.
To retrieve the information there are dataset-fetching and dataset-processing functions.

The basic parameters for the iteractions pairs are:

1. user_ids (array of np.int32) – array of user ids of the user-item pairs
2. item_ids (array of np.int32) – array of item ids of the user-item pairs

Then, several pairs of interactions can be encoded into a seuence. The basic interactions are ordered in a sequence by its timestamps and are organized into a zero-padded from the left matrix.
 

### Data provided by Spotlight

Spotlight offers 3 different kind of popular rating datasets provided as modules: 

1. [**Synthetic**](https://maciejkula.github.io/spotlight/datasets/synthetic.html):  this model contains functions for generating synthetic datasets with known properties, for model testing and experimentation. Synthetic data is information that is artificially manufactured rather than generated by real-world events. In this case it is created by a n-th order Markov Chain with uniform stationary distribution. 
1. [**Movielens**](https://maciejkula.github.io/spotlight/datasets/movielens.html): MovieLens dataset is a collection of ratings from movies. Collections have been made over various periods of time depending the dataset. Spotlight provides a module to extract the data in several datasets: 100K, 1M, 10M, and 20M. 
1. [**Goodbooks**](https://maciejkula.github.io/spotlight/datasets/goodbooks.html): This dataset contains six million ratings for ten thousand most popular (with most ratings) books. The module fetches the [Goodbooks-10K dataset](https://github.com/zygmuntz/goodbooks-10k). 


This is further explained in the read me file in the Data folder.


### Cross validation

Spotlight offers three modules with the functionality of splitting and shuffling datasets.

1. spotlight.cross_validation.random_train_test_split: Randomly split interactions between training and testing.
2. spotlight.cross_validation.shuffle_interactions: Shuffle interactions.
3. spotlight.cross_validation.user_based_train_test_split: Split interactions between a train and a test set based on user ids, so that a given user’s entire interaction history is either in the train, or the test set.


### Sequence models

Sequence models are a class of machine learning models designed to handle sequential data, where the input data is a sequence of elements (ex: time series, speech, etc.)
In this case, we consider that the sequences of users’ interactions with the items to represent them.

The sequence models available in Spotlight are the following:

1. [**Implicit feedback models**](https://maciejkula.github.io/spotlight/sequence/implicit.html): implicit feedback includes actions like clicks, views, purchases, and other interactions users have with items. These models aim to capture user preferences and patterns based on implicit user feedback (in this case, the sequence of the particular user).
This type of model is useful for recommending items given a sequence of previous items a user has interacted with.
2. [**Sequence representations**](https://maciejkula.github.io/spotlight/sequence/representations.html):


### Factorization models

Factorization models are a class of machine learning models that factorize a user-item interaction matrix into two lower-dimensional matrices. These models are designed to capture latent factors or features that represent the underlying patterns in user-item interactions. The key idea is to learn embeddings for users and items in a way that the dot product of these embeddings approximates the observed interactions.

These models are used in the context of **Collaborative filtering**. This technique is used in recommender systems to make predictions about user preferences or interests by leveraging the preferences or behaviors of a group of users. The underlying assumption is that users who have agreed in the past tend to agree again in the future. Collaborative filtering methods do not rely on explicit knowledge about items or users; instead, they identify patterns based on the preferences of a user community.

The factorization models available in Spotlight are the following:

1. [**Implicit feedback models**](https://maciejkula.github.io/spotlight/factorization/implicit.html): implicit feedback includes actions like clicks, views, purchases, and other interactions users have with items. These models aim to capture user preferences and patterns based on implicit user feedback (in this case, it is inferred from user behavior).
In Spotlight, the model is trained through negative sampling: for any known user-item pair, one or more items are randomly sampled to act as negatives (expressing a lack of preference by the user for the sampled item).
2. [**Explicit feedback models**](https://maciejkula.github.io/spotlight/factorization/explicit.html): explicit feedback typically includes explicit ratings, reviews, likes, or any other form of user-provided feedback that directly indicates the user's preference for items. These models aim to capture user preferences and patterns based on explicit user feedback (inferred from user behavior).

Both models use the class spotlight.factorization.representations.BilinearNet that gives the latent representation of users and items. The class provides a Bilinear factorization representation that encodes both users and items as an embedding layer; the score for a user-item pair is given by the dot product of the item and user latent vectors.


### Layers

Spotlight includes embedding layers useful for recommender models.

The documentation provides one layer used to compress the number of embedding parameters required by using bloom filter-like hashing and three layers that that initialise its values with a normal variable scaled.


### Loss functions

Different loss functions are prestablished into the different models. In this case: 

-. For implicit feedback models trained through negative sampling -> The pointwise, BPR, and hinge losses are a good fit 
-. For explicit feedback models, the regression and Poisson losses are used 

Nevertheless, the loss function is a parameter of all models and can be choosen freely.


### Evaluation

The following evaluating metrics are incorporated into the Spotlight library:

1. [**MRR scores**]: mean reciprocal rank (MRR) scores. One score is given for every user with interactions in the test set, representing the mean reciprocal rank of all their test items. 
2. [**MRR scores in sequence model**]: nn a sequence model, the reciprocal rank of the last element is returned for each sequence.
3. [**Precision and Recall**]: one score is given for every user with interactions in the test set, representing the Precision@k and Recall@k of all their test items.
4. [**Precision and Recall in sequence model**]: each sequence in test is split into two parts: the first part, containing all but the last k elements, is used to predict the last k elements.
5. [**RMSE**]: RMSE score for test interactions.


### Sampling

Spotlight contains a module for negative sampling which randomly samples a number of items. 
Negative sampling is a technique used to address the issue of data sparsity and improve the training efficiency of the model. The goal is to balance the training data by including negative examples, representing items that a user has not interacted with, alongside positive examples, which are items the user has interacted with or shown interest in.


### Saving a model

To save a spotlight model, you can simply use torch serialization utilities. Run these two lines:

torch.save(spotlight_model, PATH)
spotlight_model = torch.load(PATH)



